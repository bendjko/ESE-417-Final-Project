{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd   \n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Preprocessing\n",
    "\n",
    "## Importing dataset & Checking for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headerList = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar', 'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "wineData = pd.read_csv('winequality-red.csv', header = 0, names = headerList, sep=\";\")\n",
    "print(wineData.head(10))\n",
    "print(wineData)\n",
    "\n",
    "#Summarative functions\n",
    "wineData.dtypes\n",
    "wineData.describe()\n",
    "wineData.info()\n",
    "\n",
    "#Plotting histogram of each variable\n",
    "wineData.hist(alpha=0.5, figsize=(15, 10))\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for h in headerList:\n",
    "  wineData[h] = pd.to_numeric(wineData[h], errors='coerce')\n",
    "\n",
    "print(\"\\nChecking for null values: \\n\")\n",
    "wineData.isna().sum()\n",
    "wineData = wineData.fillna(0)\n",
    "print(\"\\nChecking for null values after using fillna(): \\n\")\n",
    "wineData.isna().sum()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data is imbalanced as seen from the histogram. We will adapt multiple strategies to address the issue."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploratory Data Analysis\n",
    "\n",
    "## 1. Principal Component Analysis (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA\n",
    "df_pca = wineData.copy()\n",
    "X_pca = df_pca.loc[:, 'fixed acidity':'alcohol']\n",
    "y_pca = df_pca['quality']\n",
    "\n",
    "X_pca.tail()\n",
    "X_pca = StandardScaler().fit_transform(X_pca)\n",
    "\n",
    "#Fit PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_pca)\n",
    "\n",
    "X_pca.shape\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(X_pca[:,0],X_pca[:,1],c=y_pca,cmap='rainbow')\n",
    "plt.xlabel('First principal component')\n",
    "plt.ylabel('Second Principal Component')\n",
    "plt.title(\"Using PCA to Visualize Classes\")\n",
    "plt.show()\n",
    "\n",
    "print(\"components: \", pca.components_, \"\\n\")\n",
    "print(\"explained variance: \", pca.explained_variance_, \"\\n\")\n",
    "exp_var_rat = pca.explained_variance_ratio_\n",
    "print(\"explained variance ratio: \", exp_var_rat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Correlation Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "sns.heatmap(wineData.corr(),annot=True, cmap='coolwarm',fmt='.2f')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Univariate Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test sets\n",
    "X = wineData.loc[:, 'fixed acidity':'alcohol']\n",
    "y = wineData['quality']\n",
    "\n",
    "# apply SelectKBest class to extract best features\n",
    "bestFeatures = SelectKBest(score_func=chi2, k=11)\n",
    "bestFeaturesFit = bestFeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(bestFeaturesFit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns) \n",
    "\n",
    "# concatenate scores with predictor names\n",
    "predScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "predScores.columns = ['Predictor','Score']\n",
    "print(predScores.nlargest(11,'Score'))   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping features from univariate selection\n",
    "\n",
    "### We are dropping bottom four features as they have very low predictor scores and to save computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the bottom four features (smallest score)\n",
    "wineData = wineData.drop(['density'], axis=1)\n",
    "wineData = wineData.drop(['pH'], axis=1)\n",
    "wineData = wineData.drop(['chlorides'], axis=1)\n",
    "wineData = wineData.drop(['residual sugar'], axis=1)\n",
    "wineData\n",
    "\n",
    "X = wineData.loc[:, 'fixed acidity':'alcohol']\n",
    "y = wineData['quality']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing Imbalance in Class\n",
    "\n",
    "## First Strategy: Oversampling minority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "X_over, y_over = oversample.fit_resample(X, y)\n",
    "print(\"Before RandomOverSampler : \", Counter(y))\n",
    "print(\"After RandomOverSampler : \", Counter(y_over))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second Strategy: Undersampling majority class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "print(\"Before RandomUnderSampler : \", Counter(y))\n",
    "print(\"After RandomUnderSampler : \", Counter(y_under))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third Strategy: SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoteOversample = SMOTE()\n",
    "X_smote, y_smote = smoteOversample.fit_resample(X, y)\n",
    "\n",
    "#Plotting histogram of each variable\n",
    "X_smote.hist(alpha=0.5, figsize=(15, 10))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "y_smote.hist(alpha=0.5, figsize=(15, 10))\n",
    "plt.show()\n",
    "\n",
    "from collections import Counter\n",
    "print(\"Before SMOTE : \", Counter(y))\n",
    "print(\"After SMOTE : \", Counter(y_smote))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth Strategy: Data Imputation\n",
    "### Filling in data from missing classes - 0, 1, 2, 9, & 10 with fraud data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['fixed acidity', 'volatile acidity', 'citric acid', 'free sulfur dioxide', 'total sulfur dioxide', 'sulphates', 'alcohol']\n",
    "avgX = X.mean(axis=0)\n",
    "dfImpute = pd.DataFrame([[avgX[0], avgX[1], avgX[2], avgX[3], avgX[4], avgX[5], avgX[6], 0], \n",
    "                        [avgX[0], avgX[1], avgX[2], avgX[3], avgX[4], avgX[5], avgX[6], 1],\n",
    "                        [avgX[0], avgX[1], avgX[2], avgX[3], avgX[4], avgX[5], avgX[6], 2],\n",
    "                        [avgX[0], avgX[1], avgX[2], avgX[3], avgX[4], avgX[5], avgX[6], 9],\n",
    "                        [avgX[0], avgX[1], avgX[2], avgX[3], avgX[4], avgX[5], avgX[6], 10]],\n",
    "                        columns=['fixed acidity', 'volatile acidity', 'citric acid', 'free sulfur dioxide', 'total sulfur dioxide', 'sulphates', 'alcohol', 'quality']\n",
    "                        )\n",
    "dfImpute"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Comparing Machine Learning Models / Obtaining Baseline Accuracy\n",
    "\n",
    "## Modeling - Final data preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Regular Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .2, random_state=10) #split the data\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape\n",
    "scaledData = StandardScaler()\n",
    "X_train = scaledData.fit_transform(X_train)\n",
    "X_test = scaledData.transform(X_test)\n",
    "\n",
    "# 2. Oversampled Data\n",
    "X_over_train, X_over_test, y_over_train, y_over_test = train_test_split(X_over, y_over, test_size = .2, random_state=10) #split the data\n",
    "X_over_train.shape, y_over_train.shape, X_over_test.shape, y_over_test.shape\n",
    "X_over_train = scaledData.fit_transform(X_over_train)\n",
    "X_over_test = scaledData.transform(X_over_test)\n",
    "\n",
    "# 3. Underrsampled Data\n",
    "X_under_train, X_under_test, y_under_train, y_under_test = train_test_split(X_under, y_under, test_size = .2, random_state=10) #split the data\n",
    "X_under_train.shape, y_under_train.shape, X_under_test.shape, y_under_test.shape\n",
    "X_under_train = scaledData.fit_transform(X_under_train)\n",
    "X_under_test = scaledData.transform(X_under_test)\n",
    "\n",
    "#4. SMOTE Data\n",
    "X_smote_train, X_smote_test, y_smote_train, y_smote_test = train_test_split(X_smote, y_smote, test_size = .2, random_state=10) #split the data\n",
    "X_smote_train.shape, y_smote_train.shape, X_smote_test.shape, y_smote_test.shape\n",
    "X_smote_train = scaledData.fit_transform(X_smote_train)\n",
    "X_smote_test = scaledData.transform(X_smote_test)\n",
    "\n",
    "# 5. Imputed Data\n",
    "X_impute = wineData.loc[:, 'fixed acidity':'alcohol']\n",
    "y_impute = wineData['quality']\n",
    "X_add = dfImpute.loc[:, 'fixed acidity':'alcohol']\n",
    "y_add = dfImpute['quality']\n",
    "X_impute_train, X_impute_test, y_impute_train, y_impute_test = train_test_split(X_impute, y_impute, test_size = .2, random_state=10) #split the data\n",
    "X_impute_train = X_impute_train.append(X_add)\n",
    "y_impute_train = y_impute_train.append(y_add)\n",
    "X_impute_train.shape, y_impute_train.shape, X_impute_test.shape, y_impute_test.shape\n",
    "X_impute_train = scaledData.fit_transform(X_impute_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Random Forest Classifier Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineRF = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=417)\n",
    "wineRF.fit(X_train, y_train)\n",
    "\n",
    "y_pred = wineRF.predict(X_test)\n",
    "\n",
    "#Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm)\n",
    "sns.set(font_scale=1.2) # for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()\n",
    "\n",
    "#Print classification report\n",
    "clas = classification_report(y_test, y_pred)\n",
    "print(clas)\n",
    "\n",
    "\n",
    "# Using Imputed Data\n",
    "wineRF.fit(X_impute_train, y_impute_train)\n",
    "\n",
    "y_impute_pred = wineRF.predict(X_impute_test)\n",
    "\n",
    "#Plot confusion matrix\n",
    "cm = confusion_matrix(y_impute_test, y_impute_pred)\n",
    "df_cm = pd.DataFrame(cm)\n",
    "sns.set(font_scale=1.2) # for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()\n",
    "\n",
    "#Print classification report\n",
    "clas = classification_report(y_test, y_pred)\n",
    "print(clas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machine Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineSVM = SVC(kernel = 'rbf')\n",
    "wineSVM.fit(X_train, y_train)\n",
    "y_pred = wineSVM.predict(X_test)\n",
    "\n",
    "#Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm)\n",
    "sns.set(font_scale=1.2) # for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()\n",
    "\n",
    "#Print classification report for rbf kernel\n",
    "clas1 = classification_report(y_test, y_pred)\n",
    "print(\"rbf kernel classification report: \\n\",clas1)\n",
    "\n",
    "#Print classification report for sigmoid kernel\n",
    "wineSVM = SVC(kernel = 'sigmoid')\n",
    "wineSVM.fit(X_train, y_train)\n",
    "y_pred = wineSVM.predict(X_test)\n",
    "clas2 = classification_report(y_test, y_pred)\n",
    "print(\"sigmoid kernel classification report: \\n\", clas2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineMLP = MLPClassifier(activation='logistic', solver='sgd')\n",
    "wineMLP.fit(X_train, y_train)\n",
    "y_pred = wineMLP.predict(X_test)\n",
    "\n",
    "#Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm)\n",
    "sns.set(font_scale=1.2) # for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()\n",
    "\n",
    "clas = classification_report(y_test, y_pred)\n",
    "print(clas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineLR = LogisticRegression(class_weight='balanced', random_state=417)\n",
    "wineLR.fit(X_train, y_train)\n",
    "\n",
    "y_pred = wineLR.predict(X_test)\n",
    "\n",
    "#Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "df_cm = pd.DataFrame(cm)\n",
    "sns.set(font_scale=1.2) # for label size\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 16}) # font size\n",
    "plt.show()\n",
    "\n",
    "#Print classification report\n",
    "clas = classification_report(y_test, y_pred)\n",
    "print(clas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Hyperparameter Tuning\n",
    "\n",
    "## 1. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a default random forest object\n",
    "wineRFC = RandomForestClassifier(random_state=417)\n",
    "\n",
    "#create a list of parameters you want to tune\n",
    "param_grid_RFC = { \n",
    "    'n_estimators': [100, 200, 400, 500],\n",
    "    # , 500, 700\n",
    "    'max_depth': [5,6,7],\n",
    "    # , 7, 8\n",
    "    # 'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "#fit the model using grid search\n",
    "CV_rfc = GridSearchCV(estimator=wineRFC, param_grid=param_grid_RFC, cv= 10)\n",
    "CV_rfc.fit(X_train, y_train)\n",
    "\n",
    "#print the result of best hyperparameters\n",
    "print(CV_rfc.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineSVM = SVC()\n",
    "param_grid_svm = {\n",
    "    'kernel': ['rbf','sigmoid','poly'], \n",
    "    'C': [1, 10, 100, 1000]\n",
    "}\n",
    "\n",
    "CV_svm = GridSearchCV(estimator=wineSVM, param_grid=param_grid_svm, cv= 10)\n",
    "CV_svm.fit(X_train, y_train)\n",
    "\n",
    "#print the result of best hyperparameters\n",
    "print(CV_svm.best_params_)\n",
    "           "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wineANN = MLPClassifier()\n",
    "param_grid_ann = {\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
    "    'max_iter': [100, 200, 300, 400, 500],\n",
    "}\n",
    "\n",
    "CV_svm = GridSearchCV(estimator=wineANN, param_grid=param_grid_svm, cv= 10)\n",
    "CV_svm.fit(X_train, y_train)\n",
    "\n",
    "#print the result of best hyperparameters\n",
    "print(CV_svm.best_params_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Testing Final Models\n",
    "\n",
    "## 1. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Testing best model on the test set\n",
    "## 1. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
